{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f7b7e-3ca9-4f41-adba-3a0d79b0dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c458a6-006f-4360-b751-59d1561a5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set a fixed seed\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430895ae-07d6-42b5-b0fc-6f8a75f8f1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1a7f2-e87e-4984-bf8d-582be304e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered = pd.read_csv(\"xiang_filtered.csv\")\n",
    "xiang_filtered_embeddings = torch.load(\"filtered_embeddings.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49e4cc-60aa-4dd0-adc7-1317a53c3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccad_filtered = pd.read_csv(\"clustercad_filtered.csv\")\n",
    "ccad_filtered_embeddings = torch.load(\"filtered_ccad_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff60077-3104-42b8-88b9-317006ff20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ccad_filtered))\n",
    "print(len(ccad_filtered_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803bdcb-4284-4eef-b53c-158ed490d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "to_add = [\"C\",\"C1\", \"C2\", \"B1\", \"B2\", \"A2\"]\n",
    "ccad_filtered = ccad_filtered[ccad_filtered[\"kr_type_annotation\"].isin(to_add)]\n",
    "'''\n",
    "\n",
    "to_add = [\"C\",\"C2\",\"C1\",\"B\", \"B2\",\"A\",\"A1\", \"A2\",\"B1\"]\n",
    "ccad_filtered = ccad_filtered[ccad_filtered[\"kr_type_annotation\"].isin(to_add)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c8800-a3cf-4dbe-9cb7-3d82e379c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccad_filtered[\"kr_type_annotation\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dde3e-38f6-4695-b261-5f2f83e481d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccad_filtered[ccad_filtered[\"kr_type_annotation\"] == \"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9158d-889c-4b50-b28b-615d4827ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccad_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f737d7-7138-41b9-9440-71047a35ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut 600 b1\n",
    "\n",
    "# Identify all B1 rows\n",
    "b1_mask = ccad_filtered[\"kr_type_annotation\"] == \"B1\"\n",
    "b1_indices = ccad_filtered[b1_mask].index\n",
    "\n",
    "# Randomly sample 600 B1 indices to drop\n",
    "b1_to_remove = np.random.choice(b1_indices, size=700, replace=False)\n",
    "\n",
    "# Drop those rows from the DataFrame\n",
    "ccad_filtered = ccad_filtered.drop(index=b1_to_remove)\n",
    "\n",
    "\n",
    "#cut 100 a1\n",
    "\n",
    "# Identify all B1 rows\n",
    "a1_mask = ccad_filtered[\"kr_type_annotation\"] == \"A1\"\n",
    "a1_indices = ccad_filtered[a1_mask].index\n",
    "\n",
    "# Randomly sample 600 B1 indices to drop\n",
    "a1_to_remove = np.random.choice(a1_indices, size=104, replace=False)\n",
    "\n",
    "# Drop those rows from the DataFrame\n",
    "ccad_filtered = ccad_filtered.drop(index=a1_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc87953-538f-4974-af8f-b9a969bdaf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccad_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a069ac-7ab4-4a44-90e8-d1cca7e3ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccad_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4527dd92-cb83-41a6-96f7-dc4b14475933",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_idx = xiang_filtered.index.to_numpy().tolist()\n",
    "xiang_filtered_embeddings = [xiang_filtered_embeddings[i] for i in xiang_idx]\n",
    "print(len(xiang_filtered_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7d71f-5a33-4ca2-8cae-f6c5da49dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccad_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06024cdd-fa0d-40fa-a9d5-2aa2383cbb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustercad_idx = ccad_filtered.index.to_numpy().tolist()\n",
    "ccad_filtered_embeddings = [ccad_filtered_embeddings[i] for i in clustercad_idx]\n",
    "print(len(ccad_filtered_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a317a3-074a-4a40-96c5-161a6aacb20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccad_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741d8f3-0b59-4d5f-a5a4-d35a316e5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccad_filtered = ccad_filtered.reset_index()\n",
    "xiang_filtered = xiang_filtered.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce979587-0481-4c58-9ab9-3592d481c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ccad_filtered))\n",
    "print(len(ccad_filtered_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9e786-0361-4121-897c-89c058012182",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered[\"Annotation\"] == \"B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e224dd7f-77ee-4118-ac44-44d3a40adeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f40080e-d23d-46f1-9787-1d50a244bdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e1c6f-f6ef-48c8-96d1-7449c360dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(ccad_filtered[\"kr_type_annotation\"] == \"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c716bd9-6c03-4239-959b-889dd55dc137",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cut 30 b1\n",
    "\n",
    "# Identify all B rows\n",
    "b_mask = xiang_filtered[\"Annotation\"] == \"B\"\n",
    "b_indices = xiang_filtered[b_mask].index\n",
    "\n",
    "# Randomly sample 30 B indices to drop\n",
    "b_to_remove = np.random.choice(b_indices, size=10, replace=False)\n",
    "\n",
    "# Drop those rows from the DataFrame\n",
    "xiang_filtered = xiang_filtered.drop(index=b_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10347cc1-41a7-4744-bef7-add48c1db392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xiang_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c53ba9-89ed-44d0-adc1-717efd94b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xiang_filtered_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347afe7b-d97f-4664-a954-f9e096566ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xiang_idx = xiang_filtered.index.to_numpy().tolist()\n",
    "xiang_filtered_embeddings = [xiang_filtered_embeddings[i] for i in xiang_idx]\n",
    "print(len(xiang_filtered_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e6aa5-7343-40a9-834e-67dcd737ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(xiang_filtered[xiang_filtered[\"Annotation\"] == \"B1\"]))\n",
    "print(len(ccad_filtered[ccad_filtered[\"kr_type_annotation\"] == \"B1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca78df-9268-4c9e-992d-312247246e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average pooling. \n",
    "xiang_filtered_embeddings = [x.mean(dim=1).squeeze(0) for x in xiang_filtered_embeddings]\n",
    "ccad_filtered_embeddings = [x.mean(dim=1).squeeze(0) for x in ccad_filtered_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc98b9c-00dd-4d5d-b0a0-03f3fe6b736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xiang_filtered_embeddings[0].shape)\n",
    "print(ccad_filtered_embeddings[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa8a7b0-7bc7-4157-9989-ff7a4780a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xiang_filtered_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cd0f9-2550-4cd6-8602-2592fe506d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking\n",
    "xiang_embeddings = torch.stack(xiang_filtered_embeddings)\n",
    "ccad_embeddings = torch.stack(ccad_filtered_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7af21-76f3-43b5-9fba-9ff5ea9cf5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3913ec-fe52-4bd8-9895-c21a364f0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs need to be converted to numerical values.\n",
    "\n",
    "annotations_unique = ccad_filtered[\"kr_type_annotation\"].unique()\n",
    "annotations_unique.sort() #sort alphabetically \n",
    "\n",
    "annotation_enumerated = {x: i for i, x in enumerate(annotations_unique)}\n",
    "print(annotation_enumerated)\n",
    "\n",
    "'''\n",
    "annotations_unique_cc = ccad_filtered[\"kr_type_annotation\"].unique()\n",
    "annotations_unique_cc.sort() #sort alphabetically \n",
    "\n",
    "annotation_enumerated_cc = {x: i for i, x in enumerate(annotations_unique_cc)}\n",
    "print(annotation_enumerated_cc)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0c582-1616-44a2-b453-267fe1b9cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xiang_filtered[\"Annotation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc6f2b-842b-403b-be58-ddbfbfa76a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccad_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0a9e8-0f64-4ffc-8231-6de6f859f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xiang_filtered[\"AnnotationEnumerated\"] = xiang_filtered[\"Annotation\"].map(annotation_enumerated)\n",
    "ccad_filtered[\"AnnotationEnumerated\"] = ccad_filtered[\"kr_type_annotation\"].map(annotation_enumerated)\n",
    "#ccad_filtered['AnnotationEnumerated'] = ccad_filtered['AnnotationEnumerated'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c4ec0e-977c-4e3e-ace6-7b9434817da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_enumerated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1143ba3-7fcf-4328-b30b-7c154711191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(xiang_filtered[\"AnnotationEnumerated\"])\n",
    "print(ccad_filtered[\"AnnotationEnumerated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e208d-155e-4318-a5b0-b2509e2c45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xiang_filtered_np = xiang_filtered[\"AnnotationEnumerated\"].to_list()\n",
    "ccad_filtered_np = ccad_filtered[\"AnnotationEnumerated\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1deea2-cb5a-4e93-87c2-7695b36ec265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ccad_filtered_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ed369-152a-4ad9-a893-7d620ca7e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xiang_filtered[\"Annotation\"].to_numpy()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2e55e-7491-481f-aea7-bc13fd0f1b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94078c-22ae-4a9d-961f-d75507a3541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ccad_filtered[\"kr_type_annotation\"].to_numpy()[929]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13eb5b-8f2c-44cf-b8c1-2e3c816a0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ccad_filtered_np[929]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3840192-5618-4f6b-b0a7-a2896080db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xiang_filtered_tensor = torch.tensor(xiang_filtered_np)\n",
    "#xiang_filtered_tensor = [torch.tensor(x, dtype=torch.long) for x in xiang_filtered_np]\n",
    "\n",
    "#xiang_filtered_tensor = torch.tensor(xiang_filtered_np, dtype=torch.long)\n",
    "ccad_filtered_tensor = torch.tensor(ccad_filtered_np, dtype=torch.long)\n",
    "#merged_tensor = torch.cat([xiang_filtered_tensor, ccad_filtered_tensor], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda839d-a5e9-4d5b-879a-c0ffeab40ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_embeddings = torch.cat([xiang_embeddings, ccad_embeddings], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745fc6c6-839d-4ce0-9e9f-8d0c4e93e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_tensor_merged, x_test_tensor_merged, y_train_tensor_merged, y_test_tensor_merged = train_test_split(\n",
    "    merged_embeddings,\n",
    "    merged_tensor,\n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    "    stratify=merged_tensor\n",
    ")\n",
    "\n",
    "mu_merged, sigma_merged = x_train_tensor_merged.mean(0), x_train_tensor_merged.std(0) + 1e-9\n",
    "\n",
    "x_train_tensor_merged = (x_train_tensor_merged - mu_merged) / sigma_merged\n",
    "x_test_tensor_merged = (x_test_tensor_merged - mu_merged) / sigma_merged\n",
    "\n",
    "print(\"x train len\")\n",
    "print(len(x_train_tensor_merged))\n",
    "print(\"y train len\")\n",
    "print(len(y_train_tensor_merged))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381c3ea-cfff-45fb-a76b-750e6a03c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_tensor, x_test_tensor, y_train_tensor, y_test_tensor = train_test_split(\n",
    "    ccad_embeddings,\n",
    "    ccad_filtered_tensor,\n",
    "    test_size = 0.3,\n",
    "    random_state=1,\n",
    "    stratify=ccad_filtered_tensor\n",
    ")\n",
    "\n",
    "mu, sigma = x_train_tensor.mean(0), x_train_tensor.std(0) + 1e-9\n",
    "x_train_tensor = (x_train_tensor - mu) / sigma\n",
    "x_test_tensor = (x_test_tensor - mu) / sigma\n",
    "\n",
    "print(\"x train len\")\n",
    "print(len(x_train_tensor))\n",
    "print(\"y train len\")\n",
    "print(len(y_train_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816dd75-6751-4157-b18e-1ae878b0b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.20),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.20),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.20),\n",
    "            nn.Linear(256,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.20),\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b328f76c-0a94-4c6d-a64f-83ccc7e1cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#add dropout_rate. ==\n",
    "class kr_predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(kr_predict, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(xiang_embeddings[0].shape[1], 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        self.out = nn.Linear(128, 9)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten so we're removing \n",
    "        x = self.hidden(x)\n",
    "        x = self.out(x)\n",
    "        return x      \n",
    "'''\n",
    "\n",
    "\n",
    "class kr_predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(kr_predict, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(1536, 512),     # Slightly wider first layer\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.25),\n",
    "            #nn.Linear(256, 128),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Linear(256, 9)\n",
    "    def forward(self, x):\n",
    "        #x = x.view(x.size(0), -1) # flatten so we're removing - modified so its done w/ squeeze\n",
    "        x = self.hidden(x)\n",
    "        x = self.out(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00eb36-0622-48c1-8dbb-b56e7af922ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xiang_embeddings[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739fd18-85c3-4fbf-9c4b-5c9f2c9ea679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445ce44-1803-4d4d-9532-688a86bb9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apple silicon\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is available! Using Apple Silicon GPU.\")\n",
    "else:\n",
    "    print(\"MPS is not available. CPU Fallback.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7cdb45-15f2-4071-a712-e6c97d4d1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from collections import Counter\n",
    "class_counts = Counter(y_train_tensor.numpy())\n",
    "print(\"Class distribution:\", class_counts)\n",
    "#holy fucking imbalance.\n",
    "#total_samples = sum(class_counts)\n",
    "#class_weights = [total_samples/(len(class_counts)*count) for count in class_counts]\n",
    "#class_weights = torch.FloatTensor(class_weights)\n",
    "#print(\"Class weights:\", class_weights)\n",
    "#loss = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(model.parameters(), lr = .00001)\n",
    "\n",
    "'''\n",
    "from collections import Counter\n",
    "class_counts = Counter(y_train_tensor.numpy())\n",
    "print(annotation_enumerated)\n",
    "print(\"Class distribution:\", class_counts)\n",
    "\n",
    "# Fix: Get counts in proper order (class 0, 1, 2, ..., 8) and avoid zero division\n",
    "total_samples = sum(class_counts.values())  # Sum the actual counts, not keys\n",
    "class_weights = []\n",
    "num_classes = 9\n",
    "\n",
    "\n",
    "'''\n",
    "for class_idx in range(9):  # Ensure we have weights for all 9 classes\n",
    "    count = class_counts.get(class_idx, 0)  # Get count, default to 0 if class doesn't exist\n",
    "    if count == 0:\n",
    "        weight = total_samples\n",
    "        print(f\"Warning: Class {class_idx} has 0 samples, setting high weight\")\n",
    "    else:\n",
    "        weight = total_samples / (num_classes * count)\n",
    "    class_weights.append(weight)\n",
    "\n",
    "class_weights = torch.FloatTensor(class_weights)\n",
    "print(\"Class weights:\", class_weights)\n",
    "'''\n",
    "\n",
    "class_weights = torch.tensor([\n",
    "    total_samples / (num_classes * class_counts.get(i, 1)) for i in range(num_classes)\n",
    "], dtype=torch.float32).to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "adam = optim.AdamW(model.parameters(), lr=0.001)\n",
    "#scheduler = optim.lr_scheduler.CosineAnnealingLR(adam, T_max=50)\n",
    "scheduler = optim.lr_scheduler.StepLR(adam, step_size=100, gamma=0.5)\n",
    "#every 200 epochs, cut in half 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51b714-86c7-4626-8024-b73e81da520f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b757d8f-1ad6-4375-9b9c-776b4e1e4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = x_train_tensor\n",
    "y_train_tensor = (y_train_tensor).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a3de1-c37b-4c48-8ae6-e990c862bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d12c22-8333-41b5-8084-3d35cf1f9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#use TensorDatset, DataLoader from torch utils\n",
    "\n",
    "#worked well on gamma 0.5, epoch 550, batch 8\n",
    "\n",
    "#batch_size = 32\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "#dropping last bc we are using batchnorm, so it needs >1 batch size \n",
    "\n",
    "#1500 optimal\n",
    "for epoch in range(550):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for seqs, anns in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        seqs = seqs.to(device)\n",
    "        anns = anns.to(device)\n",
    "        output = model(seqs)\n",
    "        output_loss = loss(output, anns)\n",
    "        adam.zero_grad()\n",
    "        output_loss.backward()\n",
    "        adam.step()\n",
    "        epoch_loss += output_loss.item() * seqs.size(0) #batch size scaling\n",
    "    scheduler.step()\n",
    "    avg_loss = epoch_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}: Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7407531-763b-4936-b491-d851ddf6a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "#dropping last bc we are using batchnorm, so it needs >1 batch size \n",
    "\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "def accuracy():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs) #model predictions [batch_size, 9]\n",
    "            values, predicted = torch.max(outputs.data, 1)\n",
    "            #values has highest score for each sample in batch\n",
    "            #the predicted part has the classes w/ highest score for each sample\n",
    "            total += targets.size(0) #add batch size\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            #for classification report\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    return 100 * correct/total\n",
    "\n",
    "accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcc452-cc7c-4892-916e-db6b11a6d763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fff42-d92b-4933-835c-19c87f8de428",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class_names = annotation_enumerated.keys()\n",
    "\n",
    "print(classification_report(all_targets, all_predictions, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a53edd-9a9f-4fce-b0a2-7022e50ead1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a496ce-5e42-4e51-af60-7a0a2113e5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radwatch",
   "language": "python",
   "name": "radwatch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
