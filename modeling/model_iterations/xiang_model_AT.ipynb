{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f7b7e-3ca9-4f41-adba-3a0d79b0dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba8da3-bddd-4acd-a1d8-bc1f3bc170dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add torch reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1a7f2-e87e-4984-bf8d-582be304e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered = pd.read_csv(\"kr_at_enriched_dataset.csv\")\n",
    "xiang_filtered_KR_embeddings = torch.load(\"ATTest_KR.pt\")\n",
    "xiang_filtered_AT_embeddings = torch.load(\"ATTest_AT.pt\")\n",
    "xiang_filtered_KR_embeddings = xiang_filtered_KR_embeddings[\"embeddings\"]\n",
    "xiang_filtered_AT_embeddings = xiang_filtered_AT_embeddings[\"embeddings\"]\n",
    "#test1 xiang, test2 smash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6f757-b8fd-4d13-9433-ec651cdf181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered[\"alphasub\"] = [\n",
    "    1 if any(char.isdigit() for char in str(annotation)) else 0\n",
    "    for annotation in xiang_filtered[\"Annotation\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a686004-8269-4e93-ab9f-222852ea1571",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xiang_filtered[\"at_sequence\"][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f647d9-88ec-4841-9731-6c12197edcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce032e-deab-4110-9763-58b733607ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca78df-9268-4c9e-992d-312247246e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average pooling. [len_of_seq, 1, 1536]\n",
    "\n",
    "xiang_filtered_KR_embeddings = [x.mean(dim=1).squeeze(0) for x in xiang_filtered_KR_embeddings]\n",
    "xiang_filtered_AT_embeddings = [x.mean(dim=1).squeeze(0) for x in xiang_filtered_AT_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cd0f9-2550-4cd6-8602-2592fe506d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking\n",
    "xiang_AT_embeddings = torch.stack(xiang_filtered_AT_embeddings)\n",
    "xiang_embeddings = xiang_AT_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3913ec-fe52-4bd8-9895-c21a364f0c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#outputs need to be converted to numerical values.\n",
    "\n",
    "annotations_unique = xiang_filtered[\"alphasub\"].unique()\n",
    "annotations_unique.sort() #sort alphabetically \n",
    "\n",
    "annotation_enumerated = {x: i for i, x in enumerate(annotations_unique)}\n",
    "print(annotation_enumerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0a9e8-0f64-4ffc-8231-6de6f859f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered[\"AnnotationEnumerated\"] = xiang_filtered[\"alphasub\"].map(annotation_enumerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1143ba3-7fcf-4328-b30b-7c154711191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xiang_filtered[\"AnnotationEnumerated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e208d-155e-4318-a5b0-b2509e2c45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered_np = xiang_filtered[\"AnnotationEnumerated\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3840192-5618-4f6b-b0a7-a2896080db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xiang_filtered_tensor = torch.tensor(xiang_filtered_np)\n",
    "#xiang_filtered_tensor = [torch.tensor(x, dtype=torch.long) for x in xiang_filtered_np]\n",
    "xiang_filtered_tensor = torch.tensor(xiang_filtered_np, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381c3ea-cfff-45fb-a76b-750e6a03c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_tensor, x_test_tensor, y_train_tensor, y_test_tensor = train_test_split(\n",
    "    xiang_embeddings,\n",
    "    xiang_filtered_tensor,\n",
    "    test_size = 0.2,\n",
    "    random_state=1,\n",
    "    stratify=xiang_filtered_tensor\n",
    ")\n",
    "\n",
    "mu, sigma = x_train_tensor.mean(0), x_train_tensor.std(0) + 1e-9\n",
    "x_train_tensor = (x_train_tensor - mu) / sigma\n",
    "x_test_tensor = (x_test_tensor - mu) / sigma\n",
    "\n",
    "print(\"x train len\")\n",
    "print(len(x_train_tensor))\n",
    "print(\"y train len\")\n",
    "print(len(y_train_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0f7cb-0087-4662-b77f-df9aba92a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_embeddings[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b328f76c-0a94-4c6d-a64f-83ccc7e1cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#add dropout_rate. ==\n",
    "class kr_predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(kr_predict, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(xiang_embeddings[0].shape[0], 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Linear(256, 2)\n",
    "    def forward(self, x):\n",
    "        #x = x.view(x.size(0), -1) # flatten so we're removing \n",
    "        x = self.hidden(x)\n",
    "        x = self.out(x)\n",
    "        return x      \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "class kr_predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(kr_predict, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(1536, 512),     # Slightly wider first layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        self.out = nn.Linear(128, 9)\n",
    "    def forward(self, x):\n",
    "        #x = x.view(x.size(0), -1) # flatten so we're removing - modified so its done w/ squeeze\n",
    "        x = self.hidden(x)\n",
    "        x = self.out(x)\n",
    "        return x \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00eb36-0622-48c1-8dbb-b56e7af922ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xiang_embeddings[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739fd18-85c3-4fbf-9c4b-5c9f2c9ea679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445ce44-1803-4d4d-9532-688a86bb9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apple silicon\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is available! Using Apple Silicon GPU.\")\n",
    "else:\n",
    "    print(\"MPS is not available. CPU Fallback.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cf423-d732-42ac-9313-f96d6a559536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class_counts = Counter(y_train_tensor.numpy())\n",
    "total_samples = sum(class_counts.values())\n",
    "num_classes = 2\n",
    "\n",
    "class_weights = torch.tensor([\n",
    "    total_samples / (num_classes * class_counts.get(i, 1)) for i in range(num_classes)\n",
    "], dtype=torch.float32).to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "adam = optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = optim.lr_scheduler.StepLR(adam, step_size=200, gamma=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51b714-86c7-4626-8024-b73e81da520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b757d8f-1ad6-4375-9b9c-776b4e1e4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = x_train_tensor\n",
    "y_train_tensor = (y_train_tensor).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a3de1-c37b-4c48-8ae6-e990c862bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee771f30-5dc8-4821-b246-96615405be54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d12c22-8333-41b5-8084-3d35cf1f9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "plt.ioff()\n",
    "epochs_list = []\n",
    "losses_list = []\n",
    "\n",
    "batch_size = 8\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for seqs, anns in train_loader:\n",
    "        seqs = seqs.to(device)\n",
    "        anns = anns.to(device)\n",
    "        output = model(seqs)\n",
    "        output_loss = loss(output, anns)\n",
    "        adam.zero_grad()\n",
    "        output_loss.backward()\n",
    "        adam.step()\n",
    "        epoch_loss += output_loss.item() * seqs.size(0)\n",
    "    scheduler.step()\n",
    "    avg_loss = epoch_loss / len(train_dataset)\n",
    "    epochs_list.append(epoch + 1)\n",
    "    losses_list.append(avg_loss)\n",
    "    clear_output(wait=True)\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    ax.plot(epochs_list, losses_list, 'b-', linewidth=1.5, alpha=0.9)\n",
    "    ax.set_xlim(0, 1000)\n",
    "    if len(losses_list) > 1:\n",
    "        loss_min = min(losses_list)\n",
    "        loss_max = max(losses_list)\n",
    "        loss_range = loss_max - loss_min\n",
    "        ax.set_ylim(max(0, loss_min - 0.1 * loss_range), loss_max + 0.1 * loss_range)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Average Loss', fontsize=12)\n",
    "    ax.set_title(f'LIVE Training Loss - Epoch {epoch+1} | Loss: {avg_loss:.4f}', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.plot(epochs_list[-1], losses_list[-1], 'ro', markersize=6, alpha=0.8)\n",
    "    if len(losses_list) > 1:\n",
    "        initial_loss = losses_list[0]\n",
    "        improvement = ((initial_loss - avg_loss) / initial_loss) * 100\n",
    "        ax.text(0.02, 0.98, f'Initial: {initial_loss:.4f}\\nCurrent: {avg_loss:.4f}\\nImprovement: {improvement:.1f}%', \n",
    "                transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    progress = (epoch + 1) / 1000\n",
    "    ax.axvline(x=epoch + 1, color='red', alpha=0.3, linewidth=2)\n",
    "    ax.text(epoch + 1, ax.get_ylim()[1] * 0.95, f'{progress:.1%}', \n",
    "            ha='center', fontsize=10, color='red', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7407531-763b-4936-b491-d851ddf6a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "#dropping last bc we are using batchnorm, so it needs >1 batch size \n",
    "\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "def accuracy():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs) #model predictions [batch_size, 9]\n",
    "            values, predicted = torch.max(outputs.data, 1)\n",
    "            #values has highest score for each sample in batch\n",
    "            #the predicted part has the classes w/ highest score for each sample\n",
    "            total += targets.size(0) #add batch size\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            #for classification report\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    return 100 * correct/total\n",
    "\n",
    "accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcc452-cc7c-4892-916e-db6b11a6d763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fff42-d92b-4933-835c-19c87f8de428",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class_names = ['0','1']\n",
    "print(classification_report(all_targets, all_predictions, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337d3d3-307b-471b-821f-5c9d65f4d3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945cd75-824c-47a1-98b8-ba4719215d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d841f4-4f20-48c0-a49b-4d38ea6c7a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24891e-8353-4136-a790-18ee72a44287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radwatch",
   "language": "python",
   "name": "radwatch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
