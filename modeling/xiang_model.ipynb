{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f7b7e-3ca9-4f41-adba-3a0d79b0dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba8da3-bddd-4acd-a1d8-bc1f3bc170dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add torch reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1a7f2-e87e-4984-bf8d-582be304e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered = pd.read_csv(\"xiang_filtered.csv\")\n",
    "xiang_filtered_embeddings = torch.load(\"filtered_embeddings.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773cf9c-54c7-4a39-8d3f-62cd8ae8a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_extenders = xiang_filtered[\"Extender\"].unique()\n",
    "#unique_extenders = [x for x in unique_extenders if x != pd.nan]\n",
    "unique_extenders = ['MM', 'M', 'MA21', 'MA3', 'MA10', 'MA22', 'MA5,7,8,10', 'MA15','MA4','MA6']\n",
    "xiang_filtered_extenders = xiang_filtered[xiang_filtered[\"Extender\"].isin(unique_extenders)]\n",
    "unique_extenders.sort() #sort alphabetically \n",
    "\n",
    "extenders_enumerated = {x: i for i, x in enumerate(unique_extenders)}\n",
    "print(len(extenders_enumerated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ca458-5d73-4140-b119-98401d569a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_orders = xiang_filtered[\"Order of module\"].unique()\n",
    "#unique_extenders = [x for x in unique_extenders if x != pd.nan]\n",
    "xiang_filtered_orders = xiang_filtered[xiang_filtered[\"Order of module\"].isin(unique_orders)]\n",
    "unique_orders.sort() #sort alphabetically \n",
    "\n",
    "orders_enumerated = {x: i for i, x in enumerate(unique_orders)}\n",
    "print(len(orders_enumerated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa33ec43-042e-404d-b972-76737a0c27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered[\"OrderEnumerated\"] = xiang_filtered[\"Order of module\"].map(orders_enumerated)\n",
    "orders_np = xiang_filtered[\"OrderEnumerated\"].to_numpy()\n",
    "orders_np = np.array([torch.tensor(x) for x in orders_np])\n",
    "xiang_filtered_tensor = torch.tensor(orders_np, dtype=torch.long)\n",
    "xiang_orders_onehot = (lambda x: F.one_hot(x, num_classes=28))(xiang_filtered_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f9f30-0898-453c-b327-68aaaf13cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered[\"ExtenderEnumerated\"] = xiang_filtered[\"Extender\"].map(extenders_enumerated)\n",
    "extender_np = xiang_filtered[\"ExtenderEnumerated\"].to_numpy()\n",
    "extender_np = np.array([torch.tensor(x) for x in extender_np])\n",
    "xiang_filtered_tensor = torch.tensor(extender_np, dtype=torch.long)\n",
    "xiang_extenders_onehot = (lambda x: F.one_hot(x, num_classes=10))(xiang_filtered_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a0ff9-b866-4fa7-b105-1f8b8adb0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_extenders_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556434e0-d1b1-4e9f-924a-c2fe82e75eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_orders_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9e786-0361-4121-897c-89c058012182",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca78df-9268-4c9e-992d-312247246e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average pooling. [len_of_seq, 1, 1536]\n",
    "\n",
    "\n",
    "xiang_filtered_embeddings = [x.mean(dim=1).squeeze(0) for x in xiang_filtered_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc98b9c-00dd-4d5d-b0a0-03f3fe6b736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xiang_filtered_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0431ac-47af-4879-9ac0-a6238ce79d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered_embeddings[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d405336-287e-405f-8f83-6dc3324f202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding onehot encoding\n",
    "#xiang_filtered_embeddings = [torch.cat((xiang_filtered_embeddings[i],xiang_extenders_onehot[i]), dim=0) for i in range(len(xiang_filtered_embeddings))]\n",
    "#xiang_filtered_embeddings = [torch.cat((xiang_filtered_embeddings[i],xiang_orders_onehot[i]), dim=0) for i in range(len(xiang_filtered_embeddings))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e8a7d-0fcf-4b9c-849b-5830ff11e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cd0f9-2550-4cd6-8602-2592fe506d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking\n",
    "xiang_embeddings = torch.stack(xiang_filtered_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3913ec-fe52-4bd8-9895-c21a364f0c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#outputs need to be converted to numerical values.\n",
    "\n",
    "annotations_unique = xiang_filtered[\"Annotation\"].unique()\n",
    "annotations_unique.sort() #sort alphabetically \n",
    "\n",
    "annotation_enumerated = {x: i for i, x in enumerate(annotations_unique)}\n",
    "print(annotation_enumerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0c582-1616-44a2-b453-267fe1b9cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xiang_filtered[\"Annotation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0a9e8-0f64-4ffc-8231-6de6f859f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered[\"AnnotationEnumerated\"] = xiang_filtered[\"Annotation\"].map(annotation_enumerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1143ba3-7fcf-4328-b30b-7c154711191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xiang_filtered[\"AnnotationEnumerated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e208d-155e-4318-a5b0-b2509e2c45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered_np = xiang_filtered[\"AnnotationEnumerated\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3840192-5618-4f6b-b0a7-a2896080db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xiang_filtered_tensor = torch.tensor(xiang_filtered_np)\n",
    "#xiang_filtered_tensor = [torch.tensor(x, dtype=torch.long) for x in xiang_filtered_np]\n",
    "\n",
    "xiang_filtered_tensor = torch.tensor(xiang_filtered_np, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381c3ea-cfff-45fb-a76b-750e6a03c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_tensor, x_test_tensor, y_train_tensor, y_test_tensor = train_test_split(\n",
    "    xiang_embeddings,\n",
    "    xiang_filtered_tensor,\n",
    "    test_size = 0.2,\n",
    "    random_state=1,\n",
    "    stratify=xiang_filtered_tensor\n",
    ")\n",
    "\n",
    "mu, sigma = x_train_tensor.mean(0), x_train_tensor.std(0) + 1e-9\n",
    "x_train_tensor = (x_train_tensor - mu) / sigma\n",
    "x_test_tensor = (x_test_tensor - mu) / sigma\n",
    "\n",
    "print(\"x train len\")\n",
    "print(len(x_train_tensor))\n",
    "print(\"y train len\")\n",
    "print(len(y_train_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816dd75-6751-4157-b18e-1ae878b0b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.20),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.20),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.20),\n",
    "            nn.Linear(256,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.20),\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0f7cb-0087-4662-b77f-df9aba92a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_embeddings[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b328f76c-0a94-4c6d-a64f-83ccc7e1cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#add dropout_rate. ==\n",
    "class kr_predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(kr_predict, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(xiang_embeddings[0].shape[0], 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        self.out = nn.Linear(256, 9)\n",
    "    def forward(self, x):\n",
    "        #x = x.view(x.size(0), -1) # flatten so we're removing \n",
    "        x = self.hidden(x)\n",
    "        x = self.out(x)\n",
    "        return x      \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "class kr_predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(kr_predict, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(1536, 512),     # Slightly wider first layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        self.out = nn.Linear(128, 9)\n",
    "    def forward(self, x):\n",
    "        #x = x.view(x.size(0), -1) # flatten so we're removing - modified so its done w/ squeeze\n",
    "        x = self.hidden(x)\n",
    "        x = self.out(x)\n",
    "        return x \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00eb36-0622-48c1-8dbb-b56e7af922ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xiang_embeddings[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739fd18-85c3-4fbf-9c4b-5c9f2c9ea679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445ce44-1803-4d4d-9532-688a86bb9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apple silicon\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is available! Using Apple Silicon GPU.\")\n",
    "else:\n",
    "    print(\"MPS is not available. CPU Fallback.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cf423-d732-42ac-9313-f96d6a559536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "class_counts = Counter(y_train_tensor.numpy())\n",
    "print(\"Class distribution:\", class_counts)\n",
    "#holy imbalance.\n",
    "#total_samples = sum(class_counts)\n",
    "#class_weights = [total_samples/(len(class_counts)*count) for count in class_counts]\n",
    "#class_weights = torch.FloatTensor(class_weights)\n",
    "#print(\"Class weights:\", class_weights)\n",
    "#loss = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(model.parameters(), lr = .00001)\n",
    "\n",
    "#scheduler = optim.lr_scheduler.CosineAnnealingLR(adam, T_max=50)\n",
    "#scheduler = optim.lr_scheduler.StepLR(adam, step_size=800, gamma=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51b714-86c7-4626-8024-b73e81da520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b757d8f-1ad6-4375-9b9c-776b4e1e4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = x_train_tensor\n",
    "y_train_tensor = (y_train_tensor).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a3de1-c37b-4c48-8ae6-e990c862bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee771f30-5dc8-4821-b246-96615405be54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d12c22-8333-41b5-8084-3d35cf1f9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use TensorDatset, DataLoader from torch utils\n",
    "\n",
    "batch_size = 8\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "#dropping last bc we are using batchnorm, so it needs >1 batch size \n",
    "\n",
    "for epoch in range(1500):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for seqs, anns in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        seqs = seqs.to(device)\n",
    "        anns = anns.to(device)\n",
    "        output = model(seqs)\n",
    "        output_loss = loss(output, anns)\n",
    "        adam.zero_grad()\n",
    "        output_loss.backward()\n",
    "        adam.step()\n",
    "        epoch_loss += output_loss.item() * seqs.size(0) #batch size scaling\n",
    "    avg_loss = epoch_loss / len(train_dataset)\n",
    "    #scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}: Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#visualize training loss using a graph... same simple implementation for training as shown above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7407531-763b-4936-b491-d851ddf6a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "#dropping last bc we are using batchnorm, so it needs >1 batch size \n",
    "\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "def accuracy():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs) #model predictions [batch_size, 9]\n",
    "            values, predicted = torch.max(outputs.data, 1)\n",
    "            #values has highest score for each sample in batch\n",
    "            #the predicted part has the classes w/ highest score for each sample\n",
    "            total += targets.size(0) #add batch size\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            #for classification report\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    return 100 * correct/total\n",
    "\n",
    "accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcc452-cc7c-4892-916e-db6b11a6d763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fff42-d92b-4933-835c-19c87f8de428",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class_names = ['A', 'A1', 'A2', 'B', 'B1', 'B2', 'C', 'C1', 'C2']\n",
    "print(classification_report(all_targets, all_predictions, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ad7d7-9ae6-4943-90cd-146c27784e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "xiang_filtered_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337d3d3-307b-471b-821f-5c9d65f4d3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radwatch",
   "language": "python",
   "name": "radwatch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
